<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head><title>Liquibase Enterprise Documentation</title><meta name="description" content="Liquibase Enterprise Documentation /></head>
    <body>
        <h1>Managing Database Backup and Restore</h1> <MadCap:snippetText src="../../../Resources/Snippets/images/.ver_icon_size_enterprise.flsnp" /><p /><h1 id="ManagingDatabaseBackupandRestore-Overview">Overview</h1> <MadCap:snippetText src="../../../Resources/Snippets/images/.ver_icon_size_enterprise.flsnp" /><p>The Deployment Packager performs back ups of the REF database as part of standard operation. If packaging processes DDL files using the CONVERT workflow or fails for any reason, the database is restored from that backup. This allows future Deployment Packager jobs to start from a known good state when errors are encountered or contributed changes are rejected by the Deployment Packager.&#160; This page will inform you on configuration options for the backup and restore features of Deployment Packager.</p><h1 id="ManagingDatabaseBackupandRestore-UsingStaticBackups">Using Static Backups</h1> <MadCap:snippetText src="../../../Resources/Snippets/images/.ver_icon_size_enterprise.flsnp" /><p>For large or highly complex database environments, requiring a dynamic database backup for each packaging job may significantly reduce performance. For these cases an alternative is to provide a static backup location and manage database backups directly:</p><ul><li>Backups are performed separately and not performed as part of packaging database changes.</li><li>Deployment Packager uses an existing backup file rather than creating a new one for each run.</li><li>New backups are performed manually through one of the following methods:<ul><li>Backup is performed outside of Datical</li><li>Deployment Packager is run with <code>createDatabaseBackup=true</code>&#160;and <code>preview=true&#160;</code>command-line options&#160;&#160;</li></ul></li></ul><h2 id="ManagingDatabaseBackupandRestore-AdditionalDatabaseConfigurationRequirements">Additional Database Configuration Requirements</h2><p>For Oracle, PostgreSQL, and DB2 databases there is no additional configuration required.&#160;</p><p>For SQL Server, enable OLE automation procedures on the target database as follows:&#160;</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;"><div class="codeContent panelContent pdl"><pre class="syntaxhighlighter-pre" xml:space="preserve">USE [database to backup]
GO

RECONFIGURE;

EXEC master.dbo.sp_configure 'show advanced options', 1
RECONFIGURE
GO

EXEC master.dbo.sp_configure 'Ole Automation Procedures', 1
RECONFIGURE
GO</pre></div></div><p><br /></p><h2 id="ManagingDatabaseBackupandRestore-ConfiguringDeploymentPackagerBackups">Configuring Deployment Packager Backups</h2><p>Set <code>databaseBackupMode</code> in<a href="required-deploy-packager-properties.htm"> <code>deployPackager.properties</code></a> to control backup behavior.</p><ul><li><code>always</code> - (Default). The REF database is backed up for every packaging job.&#160;</li><li><code>on_demand</code> - A full backup of the REF database is made when Deployment Packager is run with the following options:<ul><li><code>pipeline=&lt;pipelineRef&gt; </code></li><li><code>createDatabaseBackup=true </code></li></ul></li></ul><p style="margin-left: 0.0px;">You can run a backup directly using the Deployment Packager command line.&#160;&#160;</p><ul><li><code>createDatabaseBackup=true</code> - causes a new backup to be created.&#160; May be used in preview mode to create a new backup without creating new changesets. If done during packaging, the packaging must be done on a pipeline (using <code>pipeline=</code>), rather than on a DbDef.</li></ul><div class="confluence-information-macro confluence-information-macro-information conf-macro output-block"><p class="title">Best Practice</p><div class="confluence-information-macro-body"><p>The easiest way to get regular database&#160; backups to use a consistent naming convention is to run Deployment Packager to do them.&#160;The nightly database backup job is a copy of the Deployment Packager job. The copy runs Deployment Packager but does not create new changesets.&#160;</p><p>Schedule a recurring job that runs Deployment Packager with preview and backup modes set, as shown in the following example:&#160;</p><p><code>hammer groovy deployPackager.groovy pipeline=MY_PIPELINE_NAME scm=true createDatabaseBackup=true preview=true</code></p><p><br /></p></div></div><h2 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-PackagingBehavior">Packaging Behavior</h2><h3 id="ManagingDatabaseBackupandRestore-Alwaysbackup">Always backup</h3><p>When <code>databaseBackupMode</code> is set to <code>always</code>, the database is restored from the backup file in the event of packaging failure.&#160;Deploy Packager performs these operations:</p><ol><li>Back up the reference database prior to modifying the database.</li><li>Deploy new changes.</li><li>Restore from this backup if a failure occurs.</li></ol><h3 id="ManagingDatabaseBackupandRestore-OnDemandbackup">On Demand backup</h3><p>When <code>databaseBackupMode</code> is set to <code>on_demand</code>, a full restore is performed from the full backup file provided, then all existing changes are deployed to REF.&#160;Deploy Packager performs these operations:</p><ol><li>Save the existing changelog.&#160;</li><li>Restore the reference database from the backup file.&#160;</li><li><p class="auto-cursor-target">Redeploy previous changes.&#160;</p></li><li>Deploy new changes.</li><li>Deploy the original changelog to the reference database if an error occurs. This will leave the reference database in a fully deployed state.</li></ol><p><br /></p><div class="confluence-information-macro confluence-information-macro-information conf-macro output-block"><div class="confluence-information-macro-body"><p>For this process, redeployed changes are not tracked in the Deployment Monitoring Console database (DMCDB), because their deployment was already recorded. Only the new deployment creates new records in the DMCDB.&#160;</p></div></div><h2 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-Permissions">Permissions</h2><p>See the roles and permissions needed for your database in&#160;<a href="../../documentation/overview/Managed Databases.htm" rel="nofollow">Managed Databases</a></p><p>Oracle requires specific backup permissions, as noted in&#160;<a href="../../configure-databases-release-pipelines/oracle-database-setup/oracle-roles-permissions/roles-permissions-oracle.htm" rel="nofollow">Roles and Permissions for <MadCap:variable name="General.DaticalDB" /> on Oracle Database</a>.&#160;</p><p>Packager checks for the existence of the backup file.&#160; If checking fails on a permissions error, the responses depends on the setting of backupRestoreMode:</p><ul><li>ALWAYS - warn that permissions may not be set correctly and continue.&#160;</li><li>ON_DEMAND - report an error and halt.&#160;</li></ul><h2 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-ImpactonPackagingTime">Impact on Packaging Time</h2><h3 id="ManagingDatabaseBackupandRestore-PerformanceComparison">Performance Comparison</h3><p>The procedures below shows a comparison of the process in simplified form. Deploy Packager also uses the backup file internally during processing.&#160;&#160;</p><p style="margin-left: 0.0px;">Normally packaging time when always backing up depends on these operations:</p><ol><li>Back up the REF database</li><li>Package new changes</li><li>Restore the database from the backup file if an error occurs</li></ol><p style="margin-left: 0.0px;">When using a managed on_demand backup, packaging time is based on these operations:</p><ol><li>Package new changes</li><li>Restore the database from the backup if an error occurs.&#160;</li><li>Redeploy previous changes if an error occurs - <em>this time grows as additional changes are deployed</em>.</li></ol><p style="margin-left: 0.0px;">All packaging runs should experience a lower packaging time in this mode.&#160; Successful packaging runs potentially see the most performance benefit as in some cases these may now not require a backup or a restore of the REF database.</p><h3 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-TroubleshootingPerformance">Troubleshooting Performance</h3><p style="margin-left: 0.0px;">If you have implemented static/on_demand backups&#160;but have not seen a significant improvement in how long your packager jobs take to run, check your configuration.&#160; If you have set&#160;<code>databaseBackupMode=on_demand </code>but are still using&#160;<code>createDatabaseBackup=true&#160;</code>in your main packager jobs that process scripts, that is an unusual configuration.&#160; Packager will work with that configuration but it will still create a new backup file for each packager job that processes scripts, and therefore you would NOT be getting the possible performance benefit that you would have in the more typical configuration of creating a nightly backup separately with a separate packager job in preview mode and re-using that backup file when processing scripts (to avoid running backup each time).&#160; To optimize the on_demand backup, do NOT use <code>createDatabaseBackup=true&#160;</code>with your main packaging job that processes scripts (assuming that the backup file was already created and is in place).&#160;</p><p style="margin-left: 0.0px;">You can also see other possible packager performance adjustments here:&#160;<a href="improve-packager-performance.htm">How To: Improve Packager Performance</a></p><h2 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-Risks">Risks</h2><p>Although backing up the reference database during every deployment takes time, it also assures reliability.&#160; If packaging fails, the reference database is automatically restored to exactly the state it was in when packaging started.&#160; Not taking a backup every time introduces risk to the system.</p><p><span style="color: rgb(51,51,51);">In addition, any changes made to the reference database manually (outside of Datical) are not restored when using static backup file. If you make manual changes to the reference database, you should then backup the reference database and replace the backup file that Datical uses during packaging.&#160;</span></p><h1 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-TroubleshootingBackup&amp;RestoreIssues">Troubleshooting Backup &amp; Restore Issues</h1> <MadCap:snippetText src="../../../Resources/Snippets/images/.ver_icon_size_enterprise.flsnp" /><h2 style="margin-left: 0.0px;" id="ManagingDatabaseBackupandRestore-RecoveringfromaBackuporRestoreFailure">Recovering from a Backup or Restore Failure</h2><p>Occasionally an error can occur during the backup or restore phase of the Deployment Packager.&#160; Typically this happens early in the implementation process as configuration is being refined, when configuration options for backup or restore change or due to a connectivity or availability issue.&#160; Because the accurate production of new changes and the continuous automation capability of packager relies on accurate database state, the Deployment Packager should not be run until the source of the error has been addressed and the RefDB has been restored to a known good state.</p><p>As of <MadCap:variable name="General.DaticalDB" /> 7.6, execution of subsequent Deployment Packager jobs will be blocked when a backup or restore error was detected during a previous execution of the Deployment Packager.</p><h3 id="ManagingDatabaseBackupandRestore-Backup/RestoreLockFile">Backup/Restore Lock File</h3><p>When a failure is detected, <MadCap:variable name="General.DaticalDB" /> will create a .lock file in the root directory of your Datical Project and commit that to the Source Code Control repository for your project.&#160;</p><ul><li>This file follows a naming convention:&#160;<code>&lt;dbdef name&gt;.lock</code><ul><li>For example: If your DbDef name is&#160;<code>RefDB</code>&#160; the file will be named&#160;<code>RefDb.lock</code></li></ul></li><li>The file contains the error output from the backup or restore that caused it to be created.&#160; The information will also exist in the daticaldb.log file for that Deployment Packager execution.</li></ul><p>If you attempt to run the Deployment Packager again, you will get an error similar to the example below.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;"><div class="codeContent panelContent pdl"><pre class="syntaxhighlighter-pre" xml:space="preserve">===============================================================================
DATICAL DB: Packaging SQL Script(s)
===============================================================================
BEGIN: 2020-08-12-13:56:22
ERROR: Run of packager blocked due to:
ERROR: Lock file exists - 'C:\Users\ddb\git\OT_SAMPLE\OT_SAMPLE\OT_REF.lock'
ERROR: A failure has occurred during a backup or restore operation and future runs of deployPackager.groovy will be blocked as a result.
ERROR: Please address the error and run &lt;hammer groovy deployPackager.groovy MAR_2020 scm=true, preview=true, createDatabaseBackup=true clearBackupRestoreLock&gt; to unblock deployPackager.groovy
Command 'groovy deployPackager.groovy MAR_2020 scm=true preview=true createDatabaseBackup=true' exiting with error status 1</pre></div></div><p><strong>NOTE:&#160;&#160;</strong>&#160;The presence of a lock file should only block future executions of the Deployment Packager for the pipeline where the error occurred as long as each pipeline has a unique RefDB configured.</p><h3 id="ManagingDatabaseBackupandRestore-UnlockingaDaticalDBProjectafterbackup/restoreissuehasbeenresolved">Unlocking a <MadCap:variable name="General.DaticalDB" /> Project after backup/restore issue has been resolved</h3><p>Do not remove the lock until the original backup or restore issue has been investigated and resolved.&#160; Only when the issue that caused the error has been addressed and a new backup for the RefDB has been made, can the lock file be safely removed.&#160;</p><p>After the backup/restore issue is resolved, remove the lock with whichever of these methods you prefer.&#160; Note that the last option includes creating a new backup file:</p><ol><li>Delete the lock file from the Datical DB project (example:&#160;<code>RefDb.lock) a</code>nd commit the deletion to the SCM repository for that project</li><li>Or, run <code>clearBackupRestoreLock</code> sub command of the&#160;<code>deployPackager.groovy</code> script with Packager's&#160;<code>preview</code> mode enabled.&#160; Here are variations of the command, the second command also creates a new backup.<ul><li>Only clear the lock with this command:</li></ul></li></ol><div class="code panel pdl conf-macro output-block" style="border-width: 1px;"><div class="codeContent panelContent pdl"><pre class="syntaxhighlighter-pre" xml:space="preserve">hammer groovy deployPackager.groovy MAR_2020 scm=true preview=true clearBackupRestoreLock</pre></div></div><ul><li class="auto-cursor-target">Or, you can configure the command to clear the lock and also create a new backup of the RefDB:</li></ul><div class="code panel pdl conf-macro output-block" style="border-width: 1px;"><div class="codeContent panelContent pdl"><pre class="syntaxhighlighter-pre" xml:space="preserve">hammer groovy deployPackager.groovy MAR_2020 scm=true preview=true createDatabaseBackup=true clearBackupRestoreLock</pre></div></div></body>
</html>