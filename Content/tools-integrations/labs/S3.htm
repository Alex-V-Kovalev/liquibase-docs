<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" MadCap:conditions="Default.EXCLUDE">
    <head>
    </head>
    <body>
        <h1>S3</h1>
        <p><MadCap:variable name="General.Liquibase" />can integrate the use of Amazon S3 to store and retrieve data from anywhere. Extending <MadCap:variable name="General.Liquibase" />to use remote file locations addresses the DevOps persona by enabling secure, centralized file management. <MadCap:variable name="General.Liquibase" />files include changelogs, snapshots, SQL files, liquibase.properties files, native executor configuration files, checks settings configuration files and flow files.</p>
        <p>Remote file location access allows you to build a reusable repository of <MadCap:variable name="General.Liquibase" />files. It also removes the need for all developers to have local copies of Liquibase files, thus preventing drift.</p>
        <h2>First things first, S3's the realest.</h2>
        <p>Before using S3 in conjunction with Liquibase, you must have your AWS&#160;keys configured via environment variables, configuration files, . That includes the following:<br /></p>
        <p>AWS_SECRET_ACCESS_KEY</p>
        <p>AWS_ACCESS_KEY_ID</p>
        <p>AWS_REGION</p>
        <p style="font-weight: bold;">AWS_REGION rules:&#160;</p>
        <p>The AWS_REGION&#160;must be set to the region of your bucket by environment variable, on the CLI, or in the AWS configure file. You should also set a default AWS Region for accessing AWS with your application. Some operations require a Region to be set. For the best network performance, select a Region that is geographically near to you or your customers.</p>
        <h2>File Path Rules:</h2>
        <p>- You must specify the full path of any file located in your S3 bucket for <MadCap:variable name="General.Liquibase" /> to find it successfully.</p>
        <h4>Full Path Example:</h4>
        <p><code>globalVariables:<br></br>DEFAULTSFILE:&#160;"s3://mys3bucket/<MadCap:variable name="General.liquiPropFile"></MadCap:variable></code>
        </p>
        <p>- Flow files can be referenced from s3 buckets as well. One S3 file can reference another S3 which contains the desired flow file.</p>
        <p>See the example below:</p>
        <p><code>flow --flowfile=s3://myS3bucket/liquibase.s3.flowfile.yaml</code>
        </p>
        <p>- Pro license keys ca not be stored in the <MadCap:variable name="General.liquiPropFile" />file if the properties file is stored in S3 because you have to have the Pro license key to access the S3 files. It is best practice to set up an environment variable that contains the key, or export the key.</p>
        <p>Set the environment variable like so:</p>
        <p>
            <br />
        </p>
        <p>Export the key by typing the following in the CLI:</p>
        <p><code>export LIQUIBASE_LICENSE+_KEY="Enter Key Here"</code>
        </p>
        <h3>Call Bash scripts from a Flow File (ignore for now)</h3>
        <p>&#160;</p>
        <h2>Use S3 Files Locally</h2>
        <p>- In what scenario do users need to work locally?&#160;(Is this something that we need to answer or will users already know they should work locally?)</p>
        <p>Files must be in the same directory structure as they are on S3 </p>
        <h4>Related Content:</h4>
        <ul>
            <li><a href="../../enterprise/developer-get-started-guide/overview-packaging-developer.htm#https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html">AWS Bucket naming rules</a>
            </li>
        </ul>
    </body>
</html>